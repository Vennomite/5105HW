{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNsjaRjU8zhSf7J0cmI8fa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vennomite/5105HW/blob/main/Simmons_5105_HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "import scipy.stats as stats\n",
        "\n",
        "#import file\n",
        "file_path = '/content/drive/MyDrive/Intro_Machine_Learning/D3.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "#show first 10\n",
        "#data.head()\n",
        "\n",
        "#normalization. ddof=1 required for sample stdev.\n",
        "#unknown if population or sample thereof. 100 is probably a sample.\n",
        "#it won't matter much at this scale and I'd need to know the formula for it anyway.\n",
        "  #x1 = (data['X1']- np.mean(data['X1']))/np.std(data['X1'], ddof=1)\n",
        "  #x2 = (data['X2']- np.mean(data['X2']))/np.std(data['X2'], ddof=1)\n",
        "  #x3 = (data['X3']- np.mean(data['X3']))/np.std(data['X3'], ddof=1)\n",
        "\n",
        "#scipy\n",
        "x1 = stats.zscore(data['X1'], ddof = 1)\n",
        "x2 = stats.zscore(data['X2'], ddof = 1)\n",
        "x3 = stats.zscore(data['X3'], ddof = 1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#MSE, why is this called a cost function here?\n",
        "#Gradient Descent\n",
        "def Gradient_Descent(x, y, learning_rate, num_iterations):\n",
        "  n = len(data['Y'])\n",
        "  m = 0\n",
        "  b = 0\n",
        "  for i in range(num_iterations):\n",
        "    predicted_y = m*x + b\n",
        "    MSE[i] = 1/(2*n) * np.sum((predicted_y - data['Y'])**2)\n",
        "    m = m - learning_rate * (-1/n * np.sum(x * (data['Y'] - predicted_y)))\n",
        "    b = b - learning_rate * (-1/n * np.sum(data['Y'] - predicted_y))\n",
        "  return b, m\n",
        "\n",
        "#learning rate\n",
        "alpha1 = 0.01\n",
        "alpha2 = 0.06\n",
        "alpha3 = 0.0345\n",
        "alpha_multi = 0.1\n",
        "#iterations\n",
        "I = 200\n",
        "#define mse as array\n",
        "MSE = np.zeros(I)\n",
        "\n",
        "#simple linear regression x1\n",
        "#x = np.column_stack(x1).T\n",
        "#x = sm.add_constant(x)\n",
        "#model = sm.OLS(data['Y'], x).fit()\n",
        "#print(model.summary())\n",
        "\n",
        "#scatter normalized data\n",
        "  #plt.scatter(x1, data['Y'])\n",
        "  #plt.xlabel('x1')\n",
        "  #plt.ylabel('Y')\n",
        "  #plt.show()\n",
        "#boxplot real data\n",
        "  #plt.boxplot(data['X1'])\n",
        "  #plt.show()\n",
        "\n",
        "#simple linear regression x2\n",
        "#x = np.column_stack(x2).T\n",
        "#x = sm.add_constant(x)\n",
        "#model = sm.OLS(data['Y'], x).fit()\n",
        "#print(model.summary())\n",
        "\n",
        "#simple linear regression x3\n",
        "#x = np.column_stack(x3).T\n",
        "#x = sm.add_constant(x)\n",
        "#model = sm.OLS(data['Y'], x).fit()\n",
        "#print(model.summary())\n",
        "\n",
        "#multivariable regression\n",
        "#x = np.column_stack((x1, x2, x3))\n",
        "#x = sm.add_constant(x)\n",
        "#model = sm.OLS(data['Y'], x).fit()\n",
        "#print(model.summary())\n",
        "\n",
        "#regression y on x1 gradient\n",
        "Optimized_x1 = Gradient_Descent(x=x1, y=data['Y'], learning_rate = alpha1, num_iterations= I)\n",
        "print(Optimized_x1)\n",
        "print(MSE[-1])\n",
        "\n",
        "plt.scatter(x1, data['Y'])\n",
        "plt.plot(x1, Optimized_x1[0] + Optimized_x1[1]*x1, color='red')\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('Y')\n",
        "plt.show()\n",
        "\n",
        "#MSE plot\n",
        "plt.scatter(np.arange(1,I+1), MSE)\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('MSE(x1)')\n",
        "plt.title('MSE vs. Iterations')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#regression y on x2 gradient\n",
        "Optimized_x2 = Gradient_Descent(x=x2, y=data['Y'], learning_rate = alpha2, num_iterations= I)\n",
        "print(Optimized_x2)\n",
        "print(MSE[-1])\n",
        "\n",
        "plt.scatter(x2, data['Y'])\n",
        "plt.plot(x2, Optimized_x2[0] + Optimized_x2[1]*x2, color='red')\n",
        "plt.xlabel('x2')\n",
        "plt.ylabel('Y')\n",
        "plt.show()\n",
        "#MSE plot\n",
        "plt.scatter(np.arange(1,I+1), MSE)\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('MSE(x2)')\n",
        "plt.title('MSE vs. Iterations')\n",
        "plt.show()\n",
        "\n",
        "#regression y on x3 gradient\n",
        "Optimized_x3 = Gradient_Descent(x=x3, y=data['Y'], learning_rate = alpha3, num_iterations= I)\n",
        "print(Optimized_x3)\n",
        "print(MSE[-1])\n",
        "#Data plot\n",
        "plt.scatter(x3, data['Y'])\n",
        "plt.plot(x3, Optimized_x3[0] + Optimized_x3[1]*x3, color='red')\n",
        "plt.xlabel('x3')\n",
        "plt.ylabel('Y')\n",
        "plt.show()\n",
        "#MSE plot\n",
        "plt.scatter(np.arange(1,I+1), MSE)\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('MSE(x3)')\n",
        "plt.title('MSE vs. Iterations')\n",
        "plt.show()\n",
        "\n",
        "#multivariable regression gradient\n",
        "def Gradient_Descent_Multi(x, y, learning_rate, num_iterations):\n",
        "  n = len(data['Y'])\n",
        "  B0 = 0\n",
        "  B1 = 0\n",
        "  B2 = 0\n",
        "  B3 = 0\n",
        "  for i in range(num_iterations):\n",
        "    predicted_multi_y = B0 + B1*x1 + B2*x2 + B3*x3\n",
        "    MSE[i] = 1/n * np.sum((predicted_multi_y - data['Y'])**2)\n",
        "    B0 = B0 - learning_rate * (-2/n * np.sum(data['Y'] - predicted_multi_y))\n",
        "    B1 = B1 - learning_rate * (-2/n * np.sum(x1 * (data['Y'] - predicted_multi_y)))\n",
        "    B2 = B2 - learning_rate * (-2/n * np.sum(x2 * (data['Y'] - predicted_multi_y)))\n",
        "    B3 = B3 - learning_rate * (-2/n * np.sum(x3 * (data['Y'] - predicted_multi_y)))\n",
        "  return B0, B1, B2, B3\n",
        "x_group = np.column_stack((x1, x2, x3))\n",
        "print(Gradient_Descent_Multi( x_group ,y=data['Y'], learning_rate = alpha_multi, num_iterations= I))\n",
        "print(MSE[-1])\n",
        "\n",
        "\n",
        "#MSE plot\n",
        "plt.scatter(np.arange(1,I+1), MSE)\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('MSE(x1,x2,x3)')\n",
        "plt.title('MSE vs. Iterations')\n",
        "plt.show()\n",
        "\n",
        "#run values for valuations\n",
        "B0 = 1.8512492284709887\n",
        "B1 = -2.348647329679987\n",
        "B2 = 0.624227899209491\n",
        "B3 = -0.30896529609842077\n",
        "#how do I call from the previous function for b0-b3 to insert instead of having to copy output?\n",
        "#how to make this into an array that returns all y's. note* linear algebra is not something I've used in 20 years. soo... when grading\n",
        "#please give an example if possible?\n",
        "#X1 =[1,2,3]\n",
        "#X2 =[1,0,2]\n",
        "#X3 =[1,4,1]\n",
        "predict1 = B0 + B1*1 + B2*1 + B3*1\n",
        "predict2 = B0 + B1*2 + B2*0 + B3*4\n",
        "predict3 = B0 + B1*3 + B2*2 + B3*1\n",
        "\n",
        "predict = [predict1, predict2, predict3]\n",
        "\n",
        "print(predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxfCMn_KAbZW",
        "outputId": "407f1288-2b7e-475a-c68a-d270b7430820"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.18213549809792812, -4.081906615282668, -4.255202258248411]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HXEa0xBP6DQL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}